{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AlphaFold2_batch.ipynb",
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SyncFunc/DropTracking/blob/main/batch/AlphaFold2_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yBrceuFbf3"
      },
      "source": [
        "#ColabFold v1.5.5: AlphaFold2 w/ MMseqs2 BATCH\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/sokrypton/ColabFold/main/.github/ColabFold_Marv_Logo_Small.png\" height=\"256\" align=\"right\" style=\"height:256px\">\n",
        "\n",
        "Easy to use AlphaFold2 protein structure [(Jumper et al. 2021)](https://www.nature.com/articles/s41586-021-03819-2) and complex [(Evans et al. 2021)](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1) prediction using multiple sequence alignments generated through MMseqs2. For details, refer to our manuscript:\n",
        "\n",
        "[Mirdita M, Schütze K, Moriwaki Y, Heo L, Ovchinnikov S, Steinegger M. ColabFold: Making protein folding accessible to all.\n",
        "*Nature Methods*, 2022](https://www.nature.com/articles/s41592-022-01488-1)\n",
        "\n",
        "**Usage**\n",
        "\n",
        "`input_dir` directory with only fasta files or MSAs stored in Google Drive. MSAs need to be A3M formatted and have an `.a3m` extention. For MSAs MMseqs2 will not be called.\n",
        "\n",
        "`result_dir` results will be written to the result directory in Google Drive\n",
        "\n",
        "Old versions: [v1.4](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.4.0/batch/AlphaFold2_batch.ipynb), [v1.5.1](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.1/batch/AlphaFold2_batch.ipynb), [v1.5.2](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.2/batch/AlphaFold2_batch.ipynb), [v1.5.3-patch](https://colab.research.google.com/github/sokrypton/ColabFold/blob/56c72044c7d51a311ca99b953a71e552fdc042e1/batch/AlphaFold2_batch.ipynb)\n",
        "\n",
        "<strong>For more details, see <a href=\"#Instructions\">bottom</a> of the notebook and checkout the [ColabFold GitHub](https://github.com/sokrypton/ColabFold). </strong>\n",
        "\n",
        "-----------\n",
        "\n",
        "### News\n",
        "- <b><font color='green'>2023/07/31: The ColabFold MSA server is back to normal. It was using older DB (UniRef30 2202/PDB70 220313) from 27th ~8:30 AM CEST to 31st ~11:10 AM CEST.</font></b>\n",
        "- <b><font color='green'>2023/06/12: New databases! UniRef30 updated to 2023_02 and PDB to 230517. We now use PDB100 instead of PDB70 (see notes in the [main](https://colabfold.com) notebook).</font></b>\n",
        "- <b><font color='green'>2023/06/12: We introduced a new default pairing strategy: Previously, for multimer predictions with more than 2 chains, we only pair if all sequences taxonomically match (\"complete\" pairing). The new default \"greedy\" strategy pairs any taxonomically matching subsets.</font></b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwvIWN3HDyUJ",
        "outputId": "4aa3e272-83fc-4f29-d227-ad5263219fbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from sys import version_info\n",
        "python_version = f\"{version_info.major}.{version_info.minor}\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOblAo-xetgx",
        "cellView": "form"
      },
      "source": [
        "#@title Input protein sequence, then hit `Runtime` -> `Run all`\n",
        "\n",
        "input_dir = '/content/drive/MyDrive/pks/input_fasta' #@param {type:\"string\"}\n",
        "result_dir = '/content/drive/MyDrive/pks/result' #@param {type:\"string\"}\n",
        "\n",
        "# number of models to use\n",
        "#@markdown ---\n",
        "#@markdown ### Advanced settings\n",
        "msa_mode = \"MMseqs2 (UniRef+Environmental)\" #@param [\"MMseqs2 (UniRef+Environmental)\", \"MMseqs2 (UniRef only)\",\"single_sequence\",\"custom\"]\n",
        "num_models = 5 #@param [1,2,3,4,5] {type:\"raw\"}\n",
        "num_recycles = 3 #@param [1,3,6,12,24,48] {type:\"raw\"}\n",
        "stop_at_score = 100 #@param {type:\"string\"}\n",
        "#@markdown - early stop computing models once score > threshold (avg. plddt for \"structures\" and ptmscore for \"complexes\")\n",
        "use_custom_msa = False\n",
        "num_relax = 0 #@param [0, 1, 5] {type:\"raw\"}\n",
        "use_amber = num_relax > 0\n",
        "relax_max_iterations = 200 #@param [0,200,2000] {type:\"raw\"}\n",
        "use_templates = False #@param {type:\"boolean\"}\n",
        "do_not_overwrite_results = True #@param {type:\"boolean\"}\n",
        "zip_results = False #@param {type:\"boolean\"}\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iccGdbe_Pmt9",
        "cellView": "form"
      },
      "source": [
        "#@title Install dependencies\n",
        "%%bash -s $use_amber $use_templates $python_version\n",
        "\n",
        "set -e\n",
        "\n",
        "USE_AMBER=$1\n",
        "USE_TEMPLATES=$2\n",
        "PYTHON_VERSION=$3\n",
        "\n",
        "if [ ! -f COLABFOLD_READY ]; then\n",
        "  # install dependencies\n",
        "  # We have to use \"--no-warn-conflicts\" because colab already has a lot preinstalled with requirements different to ours\n",
        "  pip install -q --no-warn-conflicts \"colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold\"\n",
        "  if [ -n \"${TPU_NAME}\" ]; then\n",
        "    pip install -q --no-warn-conflicts -U dm-haiku==0.0.10 jax==0.3.25\n",
        "  fi\n",
        "  ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\n",
        "  ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\n",
        "  # hack to fix TF crash\n",
        "  rm -f /usr/local/lib/python3.*/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so\n",
        "  touch COLABFOLD_READY\n",
        "fi\n",
        "\n",
        "# Download params (~1min)\n",
        "python -m colabfold.download\n",
        "\n",
        "# setup conda\n",
        "if [ ${USE_AMBER} == \"True\" ] || [ ${USE_TEMPLATES} == \"True\" ]; then\n",
        "  if [ ! -f CONDA_READY ]; then\n",
        "    wget -qnc https://github.com/conda-forge/miniforge/releases/download/25.3.1-0/Miniforge3-25.3.1-0-Linux-x86_64.sh\n",
        "    bash Miniforge3-25.3.1-0-Linux-x86_64.sh -bfp /usr/local 2>&1 1>/dev/null\n",
        "    rm Miniforge3-25.3.1-0-Linux-x86_64.sh\n",
        "    conda config --set auto_update_conda false\n",
        "    touch CONDA_READY\n",
        "  fi\n",
        "fi\n",
        "# setup template search\n",
        "if [ ${USE_TEMPLATES} == \"True\" ] && [ ! -f HH_READY ]; then\n",
        "  conda install -y -q -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python=\"${PYTHON_VERSION}\" 2>&1 1>/dev/null\n",
        "  touch HH_READY\n",
        "fi\n",
        "# setup openmm for amber refinement\n",
        "if [ ${USE_AMBER} == \"True\" ] && [ ! -f AMBER_READY ]; then\n",
        "  conda install -y -q -c conda-forge openmm=8.2.0 python=\"${PYTHON_VERSION}\" pdbfixer 2>&1 1>/dev/null\n",
        "  touch AMBER_READY\n",
        "fi"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUYApPElB30u",
        "outputId": "42ad036f-194d-4f44-fd74-c877a7373c66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Run Prediction\n",
        "\n",
        "import sys\n",
        "\n",
        "from colabfold.batch import get_queries, run\n",
        "from colabfold.download import default_data_dir\n",
        "from colabfold.utils import setup_logging\n",
        "from pathlib import Path\n",
        "\n",
        "# For some reason we need that to get pdbfixer to import\n",
        "if use_amber and f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\n",
        "    sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\n",
        "\n",
        "setup_logging(Path(result_dir).joinpath(\"log.txt\"))\n",
        "\n",
        "queries, is_complex = get_queries(input_dir)\n",
        "run(\n",
        "    queries=queries,\n",
        "    result_dir=result_dir,\n",
        "    use_templates=use_templates,\n",
        "    num_relax=num_relax,\n",
        "    relax_max_iterations=relax_max_iterations,\n",
        "    msa_mode=msa_mode,\n",
        "    model_type=\"auto\",\n",
        "    num_models=num_models,\n",
        "    num_recycles=num_recycles,\n",
        "    model_order=[1, 2, 3, 4, 5],\n",
        "    is_complex=is_complex,\n",
        "    data_dir=default_data_dir,\n",
        "    keep_existing_results=do_not_overwrite_results,\n",
        "    rank_by=\"auto\",\n",
        "    pair_mode=\"unpaired+paired\",\n",
        "    stop_at_score=stop_at_score,\n",
        "    zip_results=zip_results,\n",
        "    user_agent=\"colabfold/google-colab-batch\",\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:56:39,331 More than one sequence in /content/drive/MyDrive/pks/input_fasta/current_query.fasta, ignoring all but the first sequence\n",
            "2025-12-11 12:56:49,341 Running on GPU\n",
            "2025-12-11 12:56:49,982 Found 5 citations for tools or databases\n",
            "2025-12-11 12:56:49,984 Query 1/1: current_query (length 431)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PENDING:   0%|          | 0/150 [elapsed: 00:00 remaining: ?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:56:50,698 Sleeping for 10s. Reason: PENDING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:   7%|▋         | 10/150 [elapsed: 00:11 remaining: 02:39]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:57:01,387 Sleeping for 10s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  13%|█▎        | 20/150 [elapsed: 00:22 remaining: 02:22]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:57:12,076 Sleeping for 10s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  20%|██        | 30/150 [elapsed: 00:32 remaining: 02:10]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:57:22,755 Sleeping for 9s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  26%|██▌       | 39/150 [elapsed: 00:42 remaining: 02:00]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:57:32,465 Sleeping for 9s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  32%|███▏      | 48/150 [elapsed: 00:52 remaining: 01:50]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:57:42,165 Sleeping for 5s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  35%|███▌      | 53/150 [elapsed: 00:57 remaining: 01:46]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:57:47,880 Sleeping for 6s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  39%|███▉      | 59/150 [elapsed: 01:04 remaining: 01:40]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:57:54,581 Sleeping for 10s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  46%|████▌     | 69/150 [elapsed: 01:15 remaining: 01:28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:58:05,270 Sleeping for 10s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  53%|█████▎    | 79/150 [elapsed: 01:25 remaining: 01:16]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:58:15,956 Sleeping for 9s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  59%|█████▊    | 88/150 [elapsed: 01:35 remaining: 01:06]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:58:25,673 Sleeping for 8s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  64%|██████▍   | 96/150 [elapsed: 01:44 remaining: 00:58]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:58:34,362 Sleeping for 10s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  71%|███████   | 106/150 [elapsed: 01:55 remaining: 00:47]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:58:45,066 Sleeping for 10s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  77%|███████▋  | 116/150 [elapsed: 02:05 remaining: 00:36]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:58:55,822 Sleeping for 8s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  83%|████████▎ | 124/150 [elapsed: 02:14 remaining: 00:28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:59:04,534 Sleeping for 8s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  88%|████████▊ | 132/150 [elapsed: 02:23 remaining: 00:19]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:59:13,234 Sleeping for 7s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  93%|█████████▎| 139/150 [elapsed: 02:30 remaining: 00:11]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:59:20,921 Sleeping for 9s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING:  99%|█████████▊| 148/150 [elapsed: 02:40 remaining: 00:02]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:59:30,608 Sleeping for 5s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING: |          | 153/? [elapsed: 02:46 remaining: 00:00]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:59:36,301 Sleeping for 10s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING: |          | 163/? [elapsed: 02:57 remaining: 00:00]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:59:46,995 Sleeping for 9s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING: |          | 172/? [elapsed: 03:06 remaining: 00:00]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 12:59:56,682 Sleeping for 8s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RUNNING: |          | 180/? [elapsed: 03:15 remaining: 00:00]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 13:00:05,379 Sleeping for 10s. Reason: RUNNING\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "COMPLETE: |          | 180/? [elapsed: 03:28 remaining: 00:00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-11 13:00:21,926 Setting max_seq=512, max_extra_seq=5120\n",
            "2025-12-11 13:02:27,380 alphafold2_ptm_model_1_seed_000 recycle=0 pLDDT=94.2 pTM=0.939\n",
            "2025-12-11 13:03:41,173 alphafold2_ptm_model_1_seed_000 recycle=1 pLDDT=94.8 pTM=0.942 tol=0.281\n",
            "2025-12-11 13:04:28,883 alphafold2_ptm_model_1_seed_000 recycle=2 pLDDT=95 pTM=0.942 tol=0.142\n",
            "2025-12-11 13:05:17,082 alphafold2_ptm_model_1_seed_000 recycle=3 pLDDT=94.9 pTM=0.94 tol=0.0569\n",
            "2025-12-11 13:05:17,083 alphafold2_ptm_model_1_seed_000 took 263.1s (3 recycles)\n",
            "2025-12-11 13:06:05,491 alphafold2_ptm_model_2_seed_000 recycle=0 pLDDT=94.8 pTM=0.948\n",
            "2025-12-11 13:06:53,598 alphafold2_ptm_model_2_seed_000 recycle=1 pLDDT=95.8 pTM=0.951 tol=0.32\n",
            "2025-12-11 13:07:41,618 alphafold2_ptm_model_2_seed_000 recycle=2 pLDDT=95.9 pTM=0.952 tol=0.0589\n",
            "2025-12-11 13:08:29,835 alphafold2_ptm_model_2_seed_000 recycle=3 pLDDT=95.8 pTM=0.951 tol=0.0484\n",
            "2025-12-11 13:08:29,836 alphafold2_ptm_model_2_seed_000 took 192.6s (3 recycles)\n",
            "2025-12-11 13:09:18,376 alphafold2_ptm_model_3_seed_000 recycle=0 pLDDT=96.2 pTM=0.954\n",
            "2025-12-11 13:10:06,795 alphafold2_ptm_model_3_seed_000 recycle=1 pLDDT=96.9 pTM=0.956 tol=0.171\n",
            "2025-12-11 13:10:54,963 alphafold2_ptm_model_3_seed_000 recycle=2 pLDDT=97.1 pTM=0.957 tol=0.0573\n",
            "2025-12-11 13:11:43,142 alphafold2_ptm_model_3_seed_000 recycle=3 pLDDT=97.1 pTM=0.956 tol=0.0363\n",
            "2025-12-11 13:11:43,143 alphafold2_ptm_model_3_seed_000 took 192.9s (3 recycles)\n",
            "2025-12-11 13:12:31,732 alphafold2_ptm_model_4_seed_000 recycle=0 pLDDT=95.6 pTM=0.952\n",
            "2025-12-11 13:13:19,918 alphafold2_ptm_model_4_seed_000 recycle=1 pLDDT=96.4 pTM=0.955 tol=0.243\n",
            "2025-12-11 13:14:08,091 alphafold2_ptm_model_4_seed_000 recycle=2 pLDDT=96.6 pTM=0.956 tol=0.0823\n",
            "2025-12-11 13:14:56,192 alphafold2_ptm_model_4_seed_000 recycle=3 pLDDT=96.7 pTM=0.955 tol=0.0421\n",
            "2025-12-11 13:14:56,193 alphafold2_ptm_model_4_seed_000 took 192.9s (3 recycles)\n",
            "2025-12-11 13:15:44,488 alphafold2_ptm_model_5_seed_000 recycle=0 pLDDT=95.9 pTM=0.953\n",
            "2025-12-11 13:16:32,733 alphafold2_ptm_model_5_seed_000 recycle=1 pLDDT=96.8 pTM=0.956 tol=0.262\n",
            "2025-12-11 13:17:20,862 alphafold2_ptm_model_5_seed_000 recycle=2 pLDDT=96.8 pTM=0.957 tol=0.119\n",
            "2025-12-11 13:18:08,970 alphafold2_ptm_model_5_seed_000 recycle=3 pLDDT=96.9 pTM=0.956 tol=0.229\n",
            "2025-12-11 13:18:08,971 alphafold2_ptm_model_5_seed_000 took 192.6s (3 recycles)\n",
            "2025-12-11 13:18:09,193 reranking models by 'plddt' metric\n",
            "2025-12-11 13:18:09,194 rank_001_alphafold2_ptm_model_3_seed_000 pLDDT=97.1 pTM=0.956\n",
            "2025-12-11 13:18:09,198 rank_002_alphafold2_ptm_model_5_seed_000 pLDDT=96.9 pTM=0.956\n",
            "2025-12-11 13:18:09,202 rank_003_alphafold2_ptm_model_4_seed_000 pLDDT=96.7 pTM=0.955\n",
            "2025-12-11 13:18:09,205 rank_004_alphafold2_ptm_model_2_seed_000 pLDDT=95.8 pTM=0.951\n",
            "2025-12-11 13:18:09,209 rank_005_alphafold2_ptm_model_1_seed_000 pLDDT=94.9 pTM=0.94\n",
            "2025-12-11 13:18:10,903 Done\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rank': [['rank_001_alphafold2_ptm_model_3_seed_000',\n",
              "   'rank_002_alphafold2_ptm_model_5_seed_000',\n",
              "   'rank_003_alphafold2_ptm_model_4_seed_000',\n",
              "   'rank_004_alphafold2_ptm_model_2_seed_000',\n",
              "   'rank_005_alphafold2_ptm_model_1_seed_000']],\n",
              " 'metric': [[{'mean_plddt': 97.125,\n",
              "    'ptm': 0.9560546875,\n",
              "    'print_line': ' pLDDT=97.1 pTM=0.956'},\n",
              "   {'mean_plddt': 96.875,\n",
              "    'ptm': 0.95556640625,\n",
              "    'print_line': ' pLDDT=96.9 pTM=0.956'},\n",
              "   {'mean_plddt': 96.6875,\n",
              "    'ptm': 0.955078125,\n",
              "    'print_line': ' pLDDT=96.7 pTM=0.955'},\n",
              "   {'mean_plddt': 95.8125,\n",
              "    'ptm': 0.95068359375,\n",
              "    'print_line': ' pLDDT=95.8 pTM=0.951'},\n",
              "   {'mean_plddt': 94.9375,\n",
              "    'ptm': 0.9404296875,\n",
              "    'print_line': ' pLDDT=94.9 pTM=0.94'}]]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGUBLzB3C6WN"
      },
      "source": [
        "# Instructions <a name=\"Instructions\"></a>\n",
        "**Quick start**\n",
        "1. Upload your single fasta files to a folder in your Google Drive\n",
        "2. Define path to the fold containing the fasta files (`input_dir`) define an outdir (`output_dir`)\n",
        "3. Press \"Runtime\" -> \"Run all\".\n",
        "\n",
        "**Result zip file contents**\n",
        "\n",
        "At the end of the job a all results `jobname.result.zip` will be uploaded to your (`output_dir`) Google Drive. Each zip contains one protein.\n",
        "\n",
        "1. PDB formatted structures sorted by avg. pIDDT. (unrelaxed and relaxed if `use_amber` is enabled).\n",
        "2. Plots of the model quality.\n",
        "3. Plots of the MSA coverage.\n",
        "4. Parameter log file.\n",
        "5. A3M formatted input MSA.\n",
        "6. BibTeX file with citations for all used tools and databases.\n",
        "\n",
        "\n",
        "**Troubleshooting**\n",
        "* Check that the runtime type is set to GPU at \"Runtime\" -> \"Change runtime type\".\n",
        "* Try to restart the session \"Runtime\" -> \"Factory reset runtime\".\n",
        "* Check your input sequence.\n",
        "\n",
        "**Known issues**\n",
        "* Google Colab assigns different types of GPUs with varying amount of memory. Some might not have enough memory to predict the structure for a long sequence.\n",
        "* Google Colab assigns different types of GPUs with varying amount of memory. Some might not have enough memory to predict the structure for a long sequence.\n",
        "* Your browser can block the pop-up for downloading the result file. You can choose the `save_to_google_drive` option to upload to Google Drive instead or manually download the result file: Click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\" (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
        "\n",
        "**Limitations**\n",
        "* Computing resources: Our MMseqs2 API can handle ~20-50k requests per day.\n",
        "* MSAs: MMseqs2 is very precise and sensitive but might find less hits compared to HHblits/HMMer searched against BFD or Mgnify.\n",
        "* We recommend to additionally use the full [AlphaFold2 pipeline](https://github.com/deepmind/alphafold).\n",
        "\n",
        "**Description of the plots**\n",
        "*   **Number of sequences per position** - We want to see at least 30 sequences per position, for best performance, ideally 100 sequences.\n",
        "*   **Predicted lDDT per position** - model confidence (out of 100) at each position. The higher the better.\n",
        "*   **Predicted Alignment Error** - For homooligomers, this could be a useful metric to assess how confident the model is about the interface. The lower the better.\n",
        "\n",
        "**Bugs**\n",
        "- If you encounter any bugs, please report the issue to https://github.com/sokrypton/ColabFold/issues\n",
        "\n",
        "**License**\n",
        "\n",
        "The source code of ColabFold is licensed under [MIT](https://raw.githubusercontent.com/sokrypton/ColabFold/main/LICENSE). Additionally, this notebook uses AlphaFold2 source code and its parameters licensed under [Apache 2.0](https://raw.githubusercontent.com/deepmind/alphafold/main/LICENSE) and  [CC BY 4.0](https://creativecommons.org/licenses/by-sa/4.0/) respectively. Read more about the AlphaFold license [here](https://github.com/deepmind/alphafold).\n",
        "\n",
        "**Acknowledgments**\n",
        "- We thank the AlphaFold team for developing an excellent model and open sourcing the software.\n",
        "\n",
        "- Do-Yoon Kim for creating the ColabFold logo.\n",
        "\n",
        "- A colab by Sergey Ovchinnikov ([@sokrypton](https://twitter.com/sokrypton)), Milot Mirdita ([@milot_mirdita](https://twitter.com/milot_mirdita)) and Martin Steinegger ([@thesteinegger](https://twitter.com/thesteinegger)).\n"
      ]
    }
  ]
}